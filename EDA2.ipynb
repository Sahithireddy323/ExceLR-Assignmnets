{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e55783aa-0952-40b8-949c-7443563824ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001FA888DF6B0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/ppscore/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001FA883D5E80>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/ppscore/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001FA8BED9B20>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/ppscore/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001FA8BEDF260>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/ppscore/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001FA8BEDD0D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/ppscore/\n",
      "ERROR: Could not find a version that satisfies the requirement ppscore (from versions: none)\n",
      "ERROR: No matching distribution found for ppscore\n"
     ]
    }
   ],
   "source": [
    "%pip install -q ppscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1ad22d2-b06b-4b31-9670-81be7c376142",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Step 0: Load the dataset\n",
    "\n",
    "# Option 1: Load from a local file\n",
    "adult_df = pd.read_csv(\"adult_with_headers.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0be25b2d-8849-4cdc-a0f8-04ab065ed568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                 age workclass        fnlwgt education  education_num  \\\n",
       " count   32561.000000     32561  3.256100e+04     32561   32561.000000   \n",
       " unique           NaN         9           NaN        16            NaN   \n",
       " top              NaN   Private           NaN   HS-grad            NaN   \n",
       " freq             NaN     22696           NaN     10501            NaN   \n",
       " mean       38.581647       NaN  1.897784e+05       NaN      10.080679   \n",
       " std        13.640433       NaN  1.055500e+05       NaN       2.572720   \n",
       " min        17.000000       NaN  1.228500e+04       NaN       1.000000   \n",
       " 25%        28.000000       NaN  1.178270e+05       NaN       9.000000   \n",
       " 50%        37.000000       NaN  1.783560e+05       NaN      10.000000   \n",
       " 75%        48.000000       NaN  2.370510e+05       NaN      12.000000   \n",
       " max        90.000000       NaN  1.484705e+06       NaN      16.000000   \n",
       " \n",
       "              marital_status       occupation relationship    race    sex  \\\n",
       " count                 32561            32561        32561   32561  32561   \n",
       " unique                    7               15            6       5      2   \n",
       " top      Married-civ-spouse   Prof-specialty      Husband   White   Male   \n",
       " freq                  14976             4140        13193   27816  21790   \n",
       " mean                    NaN              NaN          NaN     NaN    NaN   \n",
       " std                     NaN              NaN          NaN     NaN    NaN   \n",
       " min                     NaN              NaN          NaN     NaN    NaN   \n",
       " 25%                     NaN              NaN          NaN     NaN    NaN   \n",
       " 50%                     NaN              NaN          NaN     NaN    NaN   \n",
       " 75%                     NaN              NaN          NaN     NaN    NaN   \n",
       " max                     NaN              NaN          NaN     NaN    NaN   \n",
       " \n",
       "         capital_gain  capital_loss  hours_per_week  native_country  income  \n",
       " count   32561.000000  32561.000000    32561.000000           32561   32561  \n",
       " unique           NaN           NaN             NaN              42       2  \n",
       " top              NaN           NaN             NaN   United-States   <=50K  \n",
       " freq             NaN           NaN             NaN           29170   24720  \n",
       " mean     1077.648844     87.303830       40.437456             NaN     NaN  \n",
       " std      7385.292085    402.960219       12.347429             NaN     NaN  \n",
       " min         0.000000      0.000000        1.000000             NaN     NaN  \n",
       " 25%         0.000000      0.000000       40.000000             NaN     NaN  \n",
       " 50%         0.000000      0.000000       40.000000             NaN     NaN  \n",
       " 75%         0.000000      0.000000       45.000000             NaN     NaN  \n",
       " max     99999.000000   4356.000000       99.000000             NaN     NaN  ,\n",
       " age                int64\n",
       " workclass         object\n",
       " fnlwgt             int64\n",
       " education         object\n",
       " education_num      int64\n",
       " marital_status    object\n",
       " occupation        object\n",
       " relationship      object\n",
       " race              object\n",
       " sex               object\n",
       " capital_gain       int64\n",
       " capital_loss       int64\n",
       " hours_per_week     int64\n",
       " native_country    object\n",
       " income            object\n",
       " dtype: object,\n",
       " age                  0\n",
       " workclass         1836\n",
       " fnlwgt               0\n",
       " education            0\n",
       " education_num        0\n",
       " marital_status       0\n",
       " occupation        1843\n",
       " relationship         0\n",
       " race                 0\n",
       " sex                  0\n",
       " capital_gain         0\n",
       " capital_loss         0\n",
       " hours_per_week       0\n",
       " native_country     583\n",
       " income               0\n",
       " dtype: int64,\n",
       "    age  fnlwgt  education_num  capital_gain  capital_loss  hours_per_week  \\\n",
       " 0   39   77516             13          2174             0              40   \n",
       " 1   50   83311             13             0             0              13   \n",
       " 2   38  215646              9             0             0              40   \n",
       " 3   53  234721              7             0             0              40   \n",
       " 4   28  338409             13             0             0              40   \n",
       " \n",
       "     age_std  fnlwgt_std  education_num_std  capital_gain_std  \\\n",
       " 0  0.042796   -1.062722           1.128918          0.146092   \n",
       " 1  0.880288   -1.007871           1.128918         -0.147445   \n",
       " 2 -0.033340    0.244693          -0.439738         -0.147445   \n",
       " 3  1.108695    0.425240          -1.224066         -0.147445   \n",
       " 4 -0.794697    1.406658           1.128918         -0.147445   \n",
       " \n",
       "    capital_loss_std  hours_per_week_std    age_mm  fnlwgt_mm  \\\n",
       " 0         -0.218586           -0.077734  0.301370   0.043338   \n",
       " 1         -0.218586           -2.331531  0.452055   0.047277   \n",
       " 2         -0.218586           -0.077734  0.287671   0.137244   \n",
       " 3         -0.218586           -0.077734  0.493151   0.150212   \n",
       " 4         -0.218586           -0.077734  0.150685   0.220703   \n",
       " \n",
       "    education_num_mm  capital_gain_mm  capital_loss_mm  hours_per_week_mm  \n",
       " 0          0.800000          0.02174              0.0           0.397959  \n",
       " 1          0.800000          0.00000              0.0           0.122449  \n",
       " 2          0.533333          0.00000              0.0           0.397959  \n",
       " 3          0.400000          0.00000              0.0           0.397959  \n",
       " 4          0.800000          0.00000              0.0           0.397959  )"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Basic data exploration\n",
    "summary_stats = adult_df.describe(include='all')\n",
    "data_types = adult_df.dtypes\n",
    "missing_values = adult_df.isin(['?', ' ?']).sum()\n",
    "\n",
    "# Replace '?' with np.nan for proper missing value handling\n",
    "adult_df.replace(' ?', np.nan, inplace=True)\n",
    "\n",
    "# Step 2: Handle missing values - drop rows with any missing values\n",
    "adult_df_cleaned = adult_df.dropna()\n",
    "\n",
    "# Step 3: Identify numerical features\n",
    "numerical_features = adult_df_cleaned.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Apply Standard Scaling\n",
    "standard_scaler = StandardScaler()\n",
    "standard_scaled = pd.DataFrame(\n",
    "    standard_scaler.fit_transform(adult_df_cleaned[numerical_features]),\n",
    "    columns=[f\"{col}_std\" for col in numerical_features])\n",
    "    # Apply Min-Max Scaling\n",
    "minmax_scaler = MinMaxScaler()\n",
    "minmax_scaled = pd.DataFrame(\n",
    "    minmax_scaler.fit_transform(adult_df_cleaned[numerical_features]),\n",
    "    columns=[f\"{col}_mm\" for col in numerical_features]\n",
    ")\n",
    "\n",
    "# Combine original and scaled data for comparison (first 5 rows)\n",
    "scaled_comparison = pd.concat([adult_df_cleaned[numerical_features].reset_index(drop=True),\n",
    "                               standard_scaled, minmax_scaled], axis=1).head()\n",
    "\n",
    "summary_stats, data_types, missing_values, scaled_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4b14fec-1519-421e-ba3f-7353b9b275a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(workclass          7\n",
       " education         16\n",
       " marital_status     7\n",
       " occupation        14\n",
       " relationship       6\n",
       " race               5\n",
       " sex                2\n",
       " native_country    41\n",
       " dtype: int64,\n",
       "    workclass  education  marital_status  occupation  relationship  \\\n",
       " 0          5          9               4           0             1   \n",
       " 1          4          9               2           3             0   \n",
       " 2          2         11               0           5             1   \n",
       " 3          2          1               2           5             0   \n",
       " 4          2          9               2           9             5   \n",
       " \n",
       "    native_country  race_ Amer-Indian-Eskimo  race_ Asian-Pac-Islander  \\\n",
       " 0              38                     False                     False   \n",
       " 1              38                     False                     False   \n",
       " 2              38                     False                     False   \n",
       " 3              38                     False                     False   \n",
       " 4               4                     False                     False   \n",
       " \n",
       "    race_ Black  race_ Other  race_ White  sex_ Female  sex_ Male  \n",
       " 0        False        False         True        False       True  \n",
       " 1        False        False         True        False       True  \n",
       " 2        False        False         True        False       True  \n",
       " 3         True        False        False        False       True  \n",
       " 4         True        False        False         True      False  )"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = adult_df_cleaned.select_dtypes(include=['object']).columns.tolist()\n",
    "categorical_cols.remove('income')  # Exclude the target variable for now\n",
    "\n",
    "# Count unique values to determine encoding strategy\n",
    "cat_unique_counts = adult_df_cleaned[categorical_cols].nunique()\n",
    "\n",
    "# One-Hot Encoding for categorical features with <= 5 unique values\n",
    "one_hot_cols = cat_unique_counts[cat_unique_counts <= 5].index.tolist()\n",
    "one_hot_encoded = pd.get_dummies(adult_df_cleaned[one_hot_cols], prefix=one_hot_cols)\n",
    "\n",
    "# Label Encoding for categorical features with > 5 unique values\n",
    "label_encoded = adult_df_cleaned.copy()\n",
    "label_encoders = {}\n",
    "for col in cat_unique_counts[cat_unique_counts > 5].index:\n",
    "    le = LabelEncoder()\n",
    "    label_encoded[col] = le.fit_transform(label_encoded[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Combine the encoded columns for inspection\n",
    "encoded_summary = pd.concat([label_encoded[cat_unique_counts[cat_unique_counts > 5].index].head(),\n",
    "                             one_hot_encoded.head()], axis=1)\n",
    "\n",
    "cat_unique_counts, encoded_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "265cb159-4e8b-4c0d-892f-f009b69e0357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   age    age_group  capital_gain  capital_gain_log  capital_loss  capital_net\n",
       " 0   39  Middle-aged          2174          7.684784             0         2174\n",
       " 1   50  Middle-aged             0          0.000000             0            0\n",
       " 2   38  Middle-aged             0          0.000000             0            0\n",
       " 3   53  Middle-aged             0          0.000000             0            0\n",
       " 4   28        Young             0          0.000000             0            0,\n",
       " capital_gain    11.953848\n",
       " capital_loss     4.594629\n",
       " fnlwgt           1.446980\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Copy the dataset to avoid modifying the original\n",
    "df_fe = adult_df.copy()\n",
    "\n",
    "# Create new feature 1: Age Group\n",
    "# Categorize age into bins (Young: <30, Middle-aged: 30–60, Senior: >60)\n",
    "df_fe['age_group'] = pd.cut(df_fe['age'], bins=[0, 29, 59, np.inf], labels=['Young', 'Middle-aged', 'Senior'])\n",
    "\n",
    "# Create new feature 2: Capital Net Gain\n",
    "# Difference between capital_gain and capital_loss\n",
    "df_fe['capital_net'] = df_fe['capital_gain'] - df_fe['capital_loss']\n",
    "\n",
    "# Check skewness of numerical columns to identify which one to transform\n",
    "skewed_data = df_fe[['capital_gain', 'capital_loss', 'fnlwgt']].skew()\n",
    "\n",
    "# Apply log transformation to 'capital_gain' due to high skewness (only if > 0)\n",
    "df_fe['capital_gain_log'] = df_fe['capital_gain'].apply(lambda x: np.log1p(x))  # log(1 + x) for zero values\n",
    "\n",
    "# Display the new columns and skewness\n",
    "df_fe[['age', 'age_group', 'capital_gain', 'capital_gain_log', 'capital_loss', 'capital_net']].head(), skewed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c23b5765-ed0c-4da7-9088-9500daec72b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Outlier\n",
       " 1    32235\n",
       "-1      326\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Selecting only numerical columns for outlier detection\n",
    "numerical_cols = ['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week']\n",
    "numerical_data = adult_df[numerical_cols]\n",
    "\n",
    "# Applying Isolation Forest\n",
    "iso_forest = IsolationForest(contamination=0.01, random_state=42)\n",
    "outliers = iso_forest.fit_predict(numerical_data)\n",
    "\n",
    "# Mark outliers\n",
    "adult_df['Outlier'] = outliers\n",
    "\n",
    "# Count of outliers and non-outliers\n",
    "outlier_counts = adult_df['Outlier'].value_counts()\n",
    "\n",
    "# Remove outliers (where prediction == -1)\n",
    "adult_df_cleaned = adult_df[adult_df['Outlier'] == 1].drop(columns=['Outlier'])\n",
    "\n",
    "outlier_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da877ada-6e33-441f-bff3-3e5370260414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education_num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital_status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week  native_country  income  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40   United-States   <=50K  \n",
       "4             0             0              40            Cuba   <=50K  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"adult_with_headers.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows to understand the structure\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "febae16e-4e79-4cf2-92f9-f9e15f87cbb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "outlier\n",
       " 1    32235\n",
       "-1      326\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.Outlier Detection with Isolation Forest\n",
    "\n",
    "# 2.Feature Relationship Analysis using PPS and Correlation Matrix\n",
    "\n",
    "\n",
    "#Proceeding with Isolation Forest now\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Selecting numerical features for Isolation Forest\n",
    "numerical_features = ['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Apply Isolation Forest\n",
    "iso_forest = IsolationForest(contamination=0.01, random_state=42)\n",
    "outliers = iso_forest.fit_predict(scaled_data)\n",
    "\n",
    "# Add results to the dataframe\n",
    "df['outlier'] = outliers\n",
    "\n",
    "# Count of outliers detected\n",
    "outlier_counts = df['outlier'].value_counts()\n",
    "\n",
    "# Remove outliers\n",
    "df_cleaned = df[df['outlier'] == 1].drop(columns='outlier')\n",
    "\n",
    "outlier_counts\n",
    "#The Isolation Forest algorithm detected 326 outliers out of 32,561 total entries (~1%). These outliers were removed for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf9374ab-cd07-4c4f-9d9c-e00c54aba517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 32561\n",
      "Cleaned dataset size: 29305\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('adult_with_headers.csv')\n",
    "\n",
    "# Select numerical features for outlier detection\n",
    "numerical_features = ['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week']\n",
    "X = data[numerical_features]\n",
    "\n",
    "# Apply Isolation Forest\n",
    "iso_forest = IsolationForest(contamination=0.1, random_state=42)  # Assuming 10% outliers\n",
    "outlier_labels = iso_forest.fit_predict(X)\n",
    "\n",
    "# Add outlier labels to the dataset\n",
    "data['outlier'] = outlier_labels\n",
    "\n",
    "# Remove outliers (outlier_label = -1 indicates an outlier)\n",
    "cleaned_data = data[data['outlier'] == 1].drop(columns=['outlier'])\n",
    "print(f\"Original dataset size: {len(data)}\")\n",
    "print(f\"Cleaned dataset size: {len(cleaned_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4dee9ca0-d309-4a95-b6d6-faece3ddb7b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ppscore'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m      9\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mppscore\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpps\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# === Load Data ===\u001b[39;00m\n\u001b[0;32m     14\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madult_with_headers.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ppscore'"
     ]
    }
   ],
   "source": [
    "# === Imports ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import ppscore as pps\n",
    "\n",
    "# === Load Data ===\n",
    "df = pd.read_csv(\"adult_with_headers.csv\")\n",
    "df.columns = df.columns.str.strip()  # Clean column names\n",
    "\n",
    "# === Preview Data ===\n",
    "print(\"Initial shape:\", df.shape)\n",
    "display(df.head())\n",
    "\n",
    "# === Step 1: Remove Outliers using Isolation Forest (Optimized) ===\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "iso = IsolationForest(\n",
    "    contamination=0.05,\n",
    "    random_state=42,\n",
    "    n_estimators=50,       # Fewer trees to reduce computation\n",
    "    max_samples=1000       # Subsample rows for speed\n",
    ")\n",
    "outliers = iso.fit_predict(df[numeric_cols])\n",
    "df_cleaned = df[outliers == 1]  # Keep only inliers\n",
    "\n",
    "print(\"Shape after outlier removal:\", df_cleaned.shape)\n",
    "\n",
    "# === Step 2: Calculate Predictive Power Score (PPS) ===\n",
    "target = 'income'  # Change this if needed\n",
    "\n",
    "# Sample for PPS to reduce processing time\n",
    "sample_df = df_cleaned.sample(n=min(1000, len(df_cleaned)), random_state=1)\n",
    "pps_matrix = pps.matrix(sample_df)\n",
    "\n",
    "# Filter for target variable\n",
    "pps_scores = pps_matrix[pps_matrix['y'] == target].sort_values(by='ppscore', ascending=False)\n",
    "\n",
    "print(\"\\nTop Predictive Features for Target (PPS):\")\n",
    "display(pps_scores[['x', 'ppscore']])\n",
    "\n",
    "# === Step 3: Correlation Matrix Comparison (Optional) ===\n",
    "if target in numeric_cols:\n",
    "    correlation_scores = df_cleaned[numeric_cols].corr()[target].drop(target).sort_values(ascending=False)\n",
    "\n",
    "    # Merge PPS and Correlation\n",
    "    comparison_df = pd.DataFrame({\n",
    "        'Correlation': correlation_scores,\n",
    "        'PPS': pps_scores.set_index('x')['ppscore']\n",
    "    }).dropna()\n",
    "\n",
    "    print(\"\\nComparison of PPS and Correlation with Target:\")\n",
    "    display(comparison_df)\n",
    "\n",
    "    # Plot\n",
    "    comparison_df.sort_values('PPS', ascending=False).plot(kind='bar', figsize=(12, 6))\n",
    "    plt.title('PPS vs Correlation with Target')\n",
    "    plt.ylabel('Score')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"\\nTarget column '{target}' is not numeric, correlation skipped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1566dd-b5d4-4a04-9fd6-22c7de72c598",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
