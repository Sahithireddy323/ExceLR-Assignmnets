{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6bb89611-a9dc-4f03-b2c1-c1c8c2ea87e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlxtend in c:\\users\\nimma\\anaconda3\\lib\\site-packages (0.23.4)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\nimma\\anaconda3\\lib\\site-packages (from mlxtend) (1.13.1)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\nimma\\anaconda3\\lib\\site-packages (from mlxtend) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\nimma\\anaconda3\\lib\\site-packages (from mlxtend) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn>=1.3.1 in c:\\users\\nimma\\anaconda3\\lib\\site-packages (from mlxtend) (1.5.1)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\nimma\\anaconda3\\lib\\site-packages (from mlxtend) (3.9.2)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\nimma\\anaconda3\\lib\\site-packages (from mlxtend) (1.4.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\nimma\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\nimma\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\nimma\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\nimma\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nimma\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\nimma\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\nimma\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\nimma\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nimma\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nimma\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\nimma\\anaconda3\\lib\\site-packages (from scikit-learn>=1.3.1->mlxtend) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nimma\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2522bb2b-0bc5-4a6f-b93d-d6221bcd1aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shrimp,almonds,avocado,vegetables mix,green gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>burgers,meatballs,eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chutney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>turkey,avocado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mineral water,milk,energy bar,whole wheat rice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7496</th>\n",
       "      <td>butter,light mayo,fresh bread</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7497</th>\n",
       "      <td>burgers,frozen vegetables,eggs,french fries,ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7498</th>\n",
       "      <td>chicken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499</th>\n",
       "      <td>escalope,green tea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7500</th>\n",
       "      <td>eggs,frozen smoothie,yogurt cake,low fat yogurt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7501 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0\n",
       "0     shrimp,almonds,avocado,vegetables mix,green gr...\n",
       "1                                burgers,meatballs,eggs\n",
       "2                                               chutney\n",
       "3                                        turkey,avocado\n",
       "4     mineral water,milk,energy bar,whole wheat rice...\n",
       "...                                                 ...\n",
       "7496                      butter,light mayo,fresh bread\n",
       "7497  burgers,frozen vegetables,eggs,french fries,ma...\n",
       "7498                                            chicken\n",
       "7499                                 escalope,green tea\n",
       "7500    eggs,frozen smoothie,yogurt cake,low fat yogurt\n",
       "\n",
       "[7501 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load the dataset\n",
    "df = pd.read_excel(\"Online Retail.xlsx\",header=None)  \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc044b07-c1b1-4db6-ab3c-fe7abb8577d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['Items']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d8af991-2256-45c2-b95f-880797d4614e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shrimp,almonds,avocado,vegetables mix,green gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>burgers,meatballs,eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chutney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>turkey,avocado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mineral water,milk,energy bar,whole wheat rice...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Items\n",
       "0  shrimp,almonds,avocado,vegetables mix,green gr...\n",
       "1                             burgers,meatballs,eggs\n",
       "2                                            chutney\n",
       "3                                     turkey,avocado\n",
       "4  mineral water,milk,energy bar,whole wheat rice..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53437794-83ba-448e-a5f9-99056ef84105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7501 entries, 0 to 7500\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Items   7501 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 58.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a5b9f73b-2071-4930-bb04-02e789d21a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No suitable invoice column found. Check the column names in your Excel file.\n"
     ]
    }
   ],
   "source": [
    "#Data preprocessing\n",
    "#finding missing values and removing duplicate rows\n",
    "processed_df = df.copy() \n",
    "processed_df.dropna(inplace=True)\n",
    "processed_df.drop_duplicates(inplace=True)\n",
    "invoice_column = None  \n",
    "for col in ['InvoiceNo', 'invoiceno', 'Invoice Number']:\n",
    "    if col in processed_df.columns:\n",
    "        invoice_column = col\n",
    "        break  \n",
    "if invoice_column is not None:\n",
    "    if invoice_column != 'InvoiceNo':\n",
    "        processed_df.rename(columns={invoice_column: 'InvoiceNo'}, inplace=True)\n",
    "        print(f\"Column name '{invoice_column}' found and renamed to 'InvoiceNo'\")\n",
    "    processed_df['InvoiceNo'] = processed_df['InvoiceNo'].astype(str)\n",
    "    processed_df = processed_df[~processed_df['InvoiceNo'].str.contains('C')]\n",
    "else:\n",
    "    print(\"Error: No suitable invoice column found. Check the column names in your Excel file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3d90042b-c706-4ca6-a965-6bb881b5f83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  shrimp,almonds,avocado,vegetables mix,green grapes,whole weat flour,yams,cottage cheese,energy drink,tomato juice,low fat yogurt,green tea,honey,salad,mineral water,salmon,antioxydant juice,frozen smoothie,spinach,olive oil\n",
      "0                             burgers,meatballs,eggs                                                                                                                                                                             \n",
      "1                                            chutney                                                                                                                                                                             \n",
      "2                                     turkey,avocado                                                                                                                                                                             \n",
      "3  mineral water,milk,energy bar,whole wheat rice...                                                                                                                                                                             \n",
      "4                                     low fat yogurt                                                                                                                                                                             \n",
      "Warning: 'Country' column not found. Skipping missing value removal for this column.\n",
      "Error: No suitable invoice column found. Check the column names in your Excel file.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('Online retail.xlsx')\n",
    "print(df.head())\n",
    "# Make a copy of the original DataFrame to avoid modifying it directly\n",
    "processed_df = df.copy() \n",
    "if 'Country' in processed_df.columns:\n",
    "    processed_df.dropna(subset=['Country'], inplace=True)\n",
    "else:\n",
    "    print(\"Warning: 'Country' column not found. Skipping missing value removal for this column.\")\n",
    "\n",
    "# Remove duplicate rows\n",
    "processed_df.drop_duplicates(inplace=True)\n",
    "# Check if 'InvoiceNo' exists in the columns, if not, try variations\n",
    "invoice_column = None  \n",
    "for col in ['InvoiceNo', 'invoiceno', 'Invoice Number']:\n",
    "    if col in processed_df.columns:\n",
    "        invoice_column = col\n",
    "        break \n",
    "if invoice_column is not None:\n",
    "    if invoice_column != 'InvoiceNo':\n",
    "        processed_df.rename(columns={invoice_column: 'InvoiceNo'}, inplace=True)\n",
    "        print(f\"Column name '{invoice_column}' found and renamed to 'InvoiceNo'\")\n",
    "    processed_df['InvoiceNo'] = processed_df['InvoiceNo'].astype(str)\n",
    "    processed_df = processed_df[~processed_df['InvoiceNo'].str.contains('C')]\n",
    "else:\n",
    "    print(\"Error: No suitable invoice column found. Check the column names in your Excel file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b8d06c90-87ea-4bc6-bf7f-9884ff0a344a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 'InvoiceNo' column not found in processed_df. Please check your preprocessing steps.\n"
     ]
    }
   ],
   "source": [
    "#  Analysis and Interpretation:\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "# Check if 'InvoiceNo' column exists in processed_df\n",
    "if 'InvoiceNo' in processed_df.columns:\n",
    "    basket = processed_df.groupby(['InvoiceNo', 'Description'])['Quantity'].sum().unstack().reset_index().fillna(0).set_index('InvoiceNo')\n",
    "    basket[basket > 0] = 1  \n",
    "\n",
    "    # Generate frequent itemsets using apriori\n",
    "    frequent_itemsets = apriori(basket, min_support=0.01, use_colnames=True)\n",
    "\n",
    "    # Generate association rules\n",
    "    rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"Error: 'InvoiceNo' column not found in processed_df. Please check your preprocessing steps.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44740e8-45ab-484a-a3ea-dce56ae083cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interview Questions:\n",
    "# 1. What is lift and why is it important in Association rules?\n",
    "\n",
    "# Lift measures the ratio of the observed support of a rule to the expected support if the antecedent and consequent were independent.  \n",
    "# Lift > 1 implies that the items are more likely to be bought together than if they were independent. \n",
    "# Lift < 1 implies that the items are less likely to be bought together than if they were independent.\n",
    "# Lift = 1 indicates that the items are independent.\n",
    "#\n",
    "# Importance:  Lift helps to identify the truly interesting rules, filtering out those that might occur simply due to high support for individual items.  A high lift value suggests a strong association between the antecedent and the consequent that is not explainable by chance alone.  It's crucial for focusing on the most impactful relationships.\n",
    "\n",
    "\n",
    "# 2. What is support and Confidence. How do you calculate them?\n",
    "\n",
    "# Support: The support of an itemset (or rule) is the proportion of transactions in the dataset that contain that itemset.\n",
    "#    Calculation:  (Number of transactions containing the itemset) / (Total number of transactions)\n",
    "#\n",
    "# Confidence: The confidence of a rule (X => Y) is the conditional probability that a transaction containing X will also contain Y.\n",
    "#    Calculation: (Support of the itemset X ∪ Y) / (Support of the itemset X)\n",
    "#\n",
    "# Example:\n",
    "# Let's say we have 1000 transactions, and in 100 of those transactions, both item A and item B are present.\n",
    "#\n",
    "# Support(A ∪ B) = 100/1000 = 0.1\n",
    "#\n",
    "# Now, suppose that item A appears in 200 transactions.\n",
    "#\n",
    "# Support(A) = 200/1000 = 0.2\n",
    "#\n",
    "# Then the confidence of the rule A => B is:\n",
    "# Confidence(A => B) = Support(A ∪ B) / Support(A) = 0.1 / 0.2 = 0.5\n",
    "\n",
    "\n",
    "# 3. What are some limitations or challenges of Association rules mining?\n",
    "\n",
    "#  Data sparsity: Large datasets often have sparse itemsets, leading to infrequent item combinations. This results in a vast search space and can be computationally expensive.\n",
    "#\n",
    "#  High dimensionality: Datasets with many items can lead to a very high number of possible rules. This can overwhelm the system with irrelevant rules, increasing computation time and making the results difficult to analyze.\n",
    "#\n",
    "#  Minimum support and confidence thresholds: Setting appropriate thresholds for support and confidence is crucial for identifying meaningful rules. An inappropriate choice of thresholds might result in missing important patterns or discovering noisy and irrelevant relationships.\n",
    "#\n",
    "#  Scalability issues: Association rule mining can be computationally intensive, particularly for large datasets. This limits its scalability and the size of problems it can handle effectively.\n",
    "#\n",
    "#  Handling categorical and numerical data: Association rule mining is typically designed to handle categorical data. Special pre-processing is needed for numerical data before applying the algorithms.  Binning or other techniques need to be applied carefully.\n",
    "#\n",
    "#  Lack of interpretability:  While lift and confidence give information, it's still difficult to directly relate the discovered rules to specific causal relationships.\n",
    "#\n",
    "#  Inherent biases:  The data may contain inherent biases which may influence the identified patterns."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
